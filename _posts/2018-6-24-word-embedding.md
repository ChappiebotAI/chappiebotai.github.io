---
layout: post
title: A glance at Word Embedding in Natural Language Processing
author: hoangbm
---

A fundamental problem of Natural Language Processing (NLP) is how to have a good representation for words so that machines could understand and process effectively.
This issue has been tackled by many different style: from count-based methods like Bag of Word (BoW) or TF-IDF to shallow neural network like Word2Vec. These word embeddings method have been implemented heavily in our Natural Language Understanding (NLU) system as well as recommender system. In this blog, we will present these
techniques so that you could have clearer view at this interesting field in NLP.

# I) Bag of Word (BoW)

